# -*- coding: utf-8 -*-
"""MaskRCNN_Training

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1V2Vu4pCXx9QnCKoNN9PfW5V4AmV8acfC
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
ROOT_DIR = '/content/drive/MyDrive/BioVision/YARIISMA_1/MASKTRAINING/'
# %cd /content/drive/MyDrive/BioVision/YARIISMA_1/MASKTRAINING/

!pip install -r '/content/drive/MyDrive/BioVision/YARIISMA_1/MASKTRAINING/requirements.txt'

!python3 setup.py install

import os
import sys
import random
import math
import numpy as np
import skimage.io
import matplotlib
import matplotlib.pyplot as plt
import json

# Import Mask RCNN
sys.path.append(ROOT_DIR)

from mrcnn.config import Config
from mrcnn import utils
import mrcnn.model as modellib

# Path to trained weights file
COCO_WEIGHTS_PATH = os.path.join(ROOT_DIR, "mask_rcnn_coco.h5")

# Directory to save logs and model checkpoints
DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, "onur_logs2")

class CustomConfig(Config):
    NAME = "object"

    GPU_COUNT = 1

    # Must adjust this parameter accordingly to the GPU
    IMAGES_PER_GPU = 2

    # Background + iskemi, kanamalı
    NUM_CLASSES = 3  

    # Training steps per epoch
    STEPS_PER_EPOCH = 100

    # Higher validation step increases the validation accuracy but takes more time
    VALIDATION_STEPS = 10

    # Skip detections with < 80% confidence
    DETECTION_MIN_CONFIDENCE = 0.8

class CustomDataset(utils.Dataset):

    def load_custom(self, dataset_dir, subset):
        #Load a custom dataset.

        # Classes
        self.add_class("object", 1, "iskemik")
        self.add_class("object", 2, "kanamalı")

        # Train or validation dataset?
        assert subset in ["train", "val"]
        dataset_dir = os.path.join(dataset_dir, subset+"/"+subset+"-merge")

        annotations1 = json.load(open(os.path.join(ROOT_DIR, "Dataset/"+subset+"/ct_json.json")))
        annotations = list(annotations1.values())

        # Skip unannotated images
        annotations = [a for a in annotations if a['regions']]
        
        # Add images
        for a in annotations:
            polygons = [r['shape_attributes'] for r in a['regions']] 
            objects = [s['region_attributes']['names'] for s in a['regions']]
            name_dict = {"iskemik": 1,"kanamalı": 2} 
            #key = tuple(name_dict)
            num_ids = [name_dict[a] for a in objects]
     
            # load_mask() needs the image size to convert polygons to masks.
            # Unfortunately, VIA doesn't include it in JSON, and our images do not
            # have a fixed size. So we must read every image.
            image_path = os.path.join(dataset_dir, a['filename'])
            image = skimage.io.imread(image_path)
            height, width = image.shape[:2]

            self.add_image(
                "object", 
                image_id=a['filename'],
                path=image_path,
                width=width, height=height,
                polygons=polygons,
                num_ids=num_ids
                )

    def load_mask(self, image_id):
        image_info = self.image_info[image_id]
        if image_info["source"] != "object":
            return super(self.__class__, self).load_mask(image_id)

        info = self.image_info[image_id]
        if info["source"] != "object":
            return super(self.__class__, self).load_mask(image_id)
        num_ids = info['num_ids']
        mask = np.zeros([info["height"], info["width"], len(info["polygons"])],
                        dtype=np.uint8)
        for i, p in enumerate(info["polygons"]):
        	rr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])
        	mask[rr, cc, i] = 1

        # Return mask, and array of class IDs of each instance.
        num_ids = np.array(num_ids, dtype=np.int32)
        return mask, num_ids

    def image_reference(self, image_id):
        #Return the path of the image.
        info = self.image_info[image_id]
        if info["source"] == "object":
            return info["path"]
        else:
            super(self.__class__, self).image_reference(image_id)

def train(model):
    # Train set.
    train_data = CustomDataset()
    train_data.load_custom(os.path.join(ROOT_DIR, "Dataset"), "train")
    train_data.prepare()

    # Validation set.
    val_data = CustomDataset()
    val_data.load_custom(os.path.join(ROOT_DIR, "Dataset"), "val")
    val_data.prepare()

    
    model.train(train_data, val_data,
                learning_rate=config.LEARNING_RATE,
                epochs=100,
                layers='all')

config = CustomConfig()
model = modellib.MaskRCNN(mode="training", config=config, model_dir=DEFAULT_LOGS_DIR)

weights_path = COCO_WEIGHTS_PATH
if not os.path.exists(weights_path):
  utils.download_trained_weights(weights_path)

model.load_weights(weights_path, by_name=True, exclude=[
            "mrcnn_class_logits", "mrcnn_bbox_fc",
            "mrcnn_bbox", "mrcnn_mask"])

train(model)

while True:pass